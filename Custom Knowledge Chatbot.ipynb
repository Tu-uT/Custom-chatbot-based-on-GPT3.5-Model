{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6337c0b",
   "metadata": {},
   "source": [
    "# Custom Knowledge Chatbot w/ LlamaIndex\n",
    "By Liam Ottley - YouTube: https://www.youtube.com/@LiamOttley"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8911e71",
   "metadata": {},
   "source": [
    "Examples:\n",
    "- https://gita.kishans.in/\n",
    "- https://www.chatpdf.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c425f155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_index in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.5.6)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (0.5.8)\n",
      "Requirement already satisfied: langchain in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (0.0.148)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (1.24.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (8.2.2)\n",
      "Requirement already satisfied: openai>=0.26.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (0.27.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (2.0.2)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (0.3.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=0.26.4->llama_index) (2.30.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=0.26.4->llama_index) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=0.26.4->llama_index) (3.8.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->llama_index) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->llama_index) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->llama_index) (0.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain->llama_index) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain->llama_index) (1.4.48)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain->llama_index) (2.8.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain->llama_index) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain->llama_index) (1.10.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama_index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama_index) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama_index) (2023.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken->llama_index) (2023.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama_index) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama_index) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama_index) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama_index) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama_index) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama_index) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama_index) (1.3.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama_index) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2,>=1->langchain->llama_index) (4.6.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama_index) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai>=0.26.4->llama_index) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai>=0.26.4->llama_index) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai>=0.26.4->llama_index) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<2,>=1->langchain->llama_index) (2.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->openai>=0.26.4->llama_index) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json->llama_index) (1.0.0)\n",
      "Requirement already satisfied: langchain in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.148)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.4.48)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.5.8)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.10.9)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.30.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: tqdm>=4.48.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (4.65.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.48.0->langchain) (0.4.6)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama_index\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1041eae8",
   "metadata": {},
   "source": [
    "# Basic LlamaIndex Usage Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec6395b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf41880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load you data into 'Documents' a custom type by LlamaIndex\n",
    "\n",
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader('./data').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98df5bf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The constructor now takes in a list of Node objects. Since you are passing in a list of Document objects, please use `from_documents` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create an index of your documents\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPTSimpleVectorIndex\n\u001b[1;32m----> 5\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mGPTSimpleVectorIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\vector_store\\vector_indices.py:94\u001b[0m, in \u001b[0;36mGPTSimpleVectorIndex.__init__\u001b[1;34m(self, nodes, index_struct, service_context, text_qa_template, simple_vector_store_data_dict, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     simple_vector_store_data_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: index_struct\u001b[38;5;241m.\u001b[39membeddings_dict,\n\u001b[0;32m     88\u001b[0m     }\n\u001b[0;32m     90\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m SimpleVectorStore(\n\u001b[0;32m     91\u001b[0m     simple_vector_store_data_dict\u001b[38;5;241m=\u001b[39msimple_vector_store_data_dict\n\u001b[0;32m     92\u001b[0m )\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_qa_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_qa_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvector_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# TODO: Temporary hack to also store embeddings in index_struct\u001b[39;00m\n\u001b[0;32m    104\u001b[0m embedding_dict \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39membedding_dict\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:58\u001b[0m, in \u001b[0;36mGPTVectorStoreIndex.__init__\u001b[1;34m(self, nodes, index_struct, service_context, text_qa_template, vector_store, use_async, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_qa_template \u001b[38;5;241m=\u001b[39m text_qa_template \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_TEXT_QA_PROMPT\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_async \u001b[38;5;241m=\u001b[39m use_async\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\base.py:56\u001b[0m, in \u001b[0;36mBaseGPTIndex.__init__\u001b[1;34m(self, nodes, index_struct, docstore, service_context)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nodes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(nodes) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(nodes[\u001b[38;5;241m0\u001b[39m], Node):\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(nodes[\u001b[38;5;241m0\u001b[39m], Document):\n\u001b[1;32m---> 56\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     57\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe constructor now takes in a list of Node objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     58\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSince you are passing in a list of Document objects, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     59\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease use `from_documents` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     60\u001b[0m         )\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnodes must be a list of Node objects.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: The constructor now takes in a list of Node objects. Since you are passing in a list of Document objects, please use `from_documents` instead."
     ]
    }
   ],
   "source": [
    "# Create an index of your documents\n",
    "\n",
    "from llama_index import GPTSimpleVectorIndex\n",
    "\n",
    "index = GPTSimpleVectorIndex(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18731b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query your index!\n",
    "\n",
    "response = index.query(\"What do you think of Facebook's LLaMa?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57864389",
   "metadata": {},
   "source": [
    "# Customize your LLM for different output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c726dc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:root:> [build_index_from_documents] Total embedding token usage: 1321 tokens\n"
     ]
    }
   ],
   "source": [
    "# Setup your LLM\n",
    "\n",
    "from llama_index import LLMPredictor, GPTSimpleVectorIndex, PromptHelper\n",
    "\n",
    "\n",
    "# define LLM\n",
    "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.1, model_name=\"text-davinci-002\"))\n",
    "\n",
    "# define prompt helper\n",
    "# set maximum input size\n",
    "max_input_size = 4096\n",
    "# set number of output tokens\n",
    "num_output = 256\n",
    "# set maximum chunk overlap\n",
    "max_chunk_overlap = 20\n",
    "prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)\n",
    "\n",
    "custom_LLM_index = GPTSimpleVectorIndex(\n",
    "    documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f359b0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 1369 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I think it's a great idea!\n"
     ]
    }
   ],
   "source": [
    "# Query your index!\n",
    "\n",
    "response = custom_LLM_index.query(\"What do you think of Facebook's LLaMa?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f4e5c",
   "metadata": {},
   "source": [
    "# Wikipedia Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4db9772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import download_loader\n",
    "\n",
    "WikipediaReader = download_loader(\"WikipediaReader\")\n",
    "\n",
    "loader = WikipediaReader()\n",
    "wikidocs = loader.load_data(pages=['Cyclone Freddy'])\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Cyclone_Freddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "941c9bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:root:> [build_index_from_documents] Total embedding token usage: 4103 tokens\n"
     ]
    }
   ],
   "source": [
    "wiki_index = GPTSimpleVectorIndex(wikidocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e4a4dd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 3844 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cyclone Freddy is a very intense tropical cyclone that affected the Mascarene Islands, Madagascar, Mozambique, and Zimbabwe in February 2023. It is the longest-lived tropical cyclone on record, surpassing Hurricane John's record of 31 days. Freddy was once a powerful cyclone that was classified as a Category 5-equivalent tropical cyclone by the Joint Typhoon Warning Center (JTWC). It caused widespread damage and at least 29 deaths in Madagascar, Mozambique, and Zimbabwe. In Madagascar, over 14,000 homes were affected, with 5,500 destroyed, 3,079 flooded, and at least 9,696 damaged. At least 24,358 people were displaced, and nearly 25,000 customers were left without power at the height of the cyclone. In Saint-Paul, 20 tons of mangoes were destroyed, and Highway RD48 in Salazie was closed due to a landslide. Eleven mobile sites maintained by Orange S.A. were knocked offline in Tampon, Saint-Louis, and Saint-Paul.\n"
     ]
    }
   ],
   "source": [
    "response = wiki_index.query(\"What is cyclone freddy?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebea2acc",
   "metadata": {},
   "source": [
    "# Customer Support Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "19f396a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('./asos').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cb30944e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:root:> [build_index_from_documents] Total embedding token usage: 12584 tokens\n"
     ]
    }
   ],
   "source": [
    "index = GPTSimpleVectorIndex(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "946c44ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 1317 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In the United Arab Emirates, you have the option of signing up for ASOS Premier, which gives you free Standard and Express delivery all year round when you spend over 150 AED. It costs 200 AED and is valid on the order you purchase it on.\n"
     ]
    }
   ],
   "source": [
    "response = index.query(\"What premier service options do I have in the UAE?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e77e646",
   "metadata": {},
   "source": [
    "# YouTube Video Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "89160742",
   "metadata": {},
   "outputs": [],
   "source": [
    "YoutubeTranscriptReader = download_loader(\"YoutubeTranscriptReader\")\n",
    "\n",
    "loader = YoutubeTranscriptReader()\n",
    "documents = loader.load_data(ytlinks=['https://www.youtube.com/watch?v=K7Kh9Ntd8VE&ab_channel=DaveNick'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0995d23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:root:> [build_index_from_documents] Total embedding token usage: 18181 tokens\n"
     ]
    }
   ],
   "source": [
    "index = GPTSimpleVectorIndex(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "194e88fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 4024 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Re-uploading other people's content without permission.\n",
      "2. Using copyrighted music.\n",
      "3. Not understanding how the YouTube algorithm works.\n",
      "4. Not researching the best niche for YouTube automation.\n",
      "5. Not optimizing the About section with relevant keywords.\n",
      "6. Not creating a logo and channel art that is professional and attractive.\n"
     ]
    }
   ],
   "source": [
    "response = index.query(\"What some YouTube automation mistakes to avoid?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a05da",
   "metadata": {},
   "source": [
    "# Chatbot Class - Just include your index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65a0e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "class Chatbot:\n",
    "    def __init__(self, api_key, index):\n",
    "        self.index = index\n",
    "        openai.api_key = api_key\n",
    "        self.chat_history = []\n",
    "\n",
    "    def generate_response(self, user_input):\n",
    "        prompt = \"\\n\".join([f\"{message['role']}: {message['content']}\" for message in self.chat_history[-5:]])\n",
    "        prompt += f\"\\nUser: {user_input}\"\n",
    "        response = index.query(user_input)\n",
    "\n",
    "        message = {\"role\": \"assistant\", \"content\": response.response}\n",
    "        self.chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        self.chat_history.append(message)\n",
    "        return message\n",
    "    \n",
    "    def load_chat_history(self, filename):\n",
    "        try:\n",
    "            with open(filename, 'r') as f:\n",
    "                self.chat_history = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "    def save_chat_history(self, filename):\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(self.chat_history, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d3da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('./data').load_data()\n",
    "index = GPTSimpleVectorIndex(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24576df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap out your index below for whatever knowledge base you want\n",
    "bot = Chatbot(\"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\", index=index)\n",
    "bot.load_chat_history(\"chat_history.json\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"bye\", \"goodbye\"]:\n",
    "        print(\"Bot: Goodbye!\")\n",
    "        bot.save_chat_history(\"chat_history.json\")\n",
    "        break\n",
    "    response = bot.generate_response(user_input)\n",
    "    print(f\"Bot: {response['content']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
